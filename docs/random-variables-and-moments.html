<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Random variables and moments | Mathematical Notes for Machine Learning</title>
  <meta name="description" content="Chapter 12 Random variables and moments | Mathematical Notes for Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Random variables and moments | Mathematical Notes for Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="enixam/math-foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Random variables and moments | Mathematical Notes for Machine Learning" />
  
  
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-09-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics-of-probability-theory.html"/>
<link rel="next" href="univariate-distributions.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math Notes for Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Linear Algebra</b></span></li>
<li class="chapter" data-level="1" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html"><i class="fa fa-check"></i><b>1</b> Basic Matrix Algebra</a><ul>
<li class="chapter" data-level="1.1" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.1</b> Matrix Multiplication</a><ul>
<li class="chapter" data-level="1.1.1" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#geometric-transformations"><i class="fa fa-check"></i><b>1.1.1</b> Geometric Transformations</a></li>
<li class="chapter" data-level="1.1.2" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#selector-matrix"><i class="fa fa-check"></i><b>1.1.2</b> Selector matrix</a></li>
<li class="chapter" data-level="1.1.3" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#discrete-convolution"><i class="fa fa-check"></i><b>1.1.3</b> Discrete Convolution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#elemetary-matrix-and-row-operations"><i class="fa fa-check"></i><b>1.2</b> Elemetary matrix and row operations</a></li>
<li class="chapter" data-level="1.3" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#lu-factorization"><i class="fa fa-check"></i><b>1.3</b> LU Factorization</a></li>
<li class="chapter" data-level="1.4" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#determinants"><i class="fa fa-check"></i><b>1.4</b> Determinants</a><ul>
<li class="chapter" data-level="1.4.1" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#cofactor-expansion"><i class="fa fa-check"></i><b>1.4.1</b> Cofactor Expansion</a></li>
<li class="chapter" data-level="1.4.2" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#geometric-interpretation-of-determinant"><i class="fa fa-check"></i><b>1.4.2</b> Geometric Interpretation of Determinant</a></li>
<li class="chapter" data-level="1.4.3" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#properties-of-determinant"><i class="fa fa-check"></i><b>1.4.3</b> Properties of Determinant</a></li>
<li class="chapter" data-level="1.4.4" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#cramers-rule"><i class="fa fa-check"></i><b>1.4.4</b> Cramerâ€™s Rule</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#trace"><i class="fa fa-check"></i><b>1.5</b> Trace</a></li>
<li class="chapter" data-level="1.6" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#matrix-inversion"><i class="fa fa-check"></i><b>1.6</b> Matrix Inversion</a><ul>
<li class="chapter" data-level="1.6.1" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#the-matrix-inversion-lemma"><i class="fa fa-check"></i><b>1.6.1</b> The Matrix Inversion Lemma</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#matrix-multiplication-as-linear-transformation"><i class="fa fa-check"></i><b>1.7</b> Matrix Multiplication as Linear Transformation</a></li>
<li class="chapter" data-level="1.8" data-path="basic-matrix-algebra.html"><a href="basic-matrix-algebra.html#complexity-of-matrix-computation"><i class="fa fa-check"></i><b>1.8</b> Complexity of Matrix Computation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="vector-spaces.html"><a href="vector-spaces.html"><i class="fa fa-check"></i><b>2</b> Vector Spaces</a><ul>
<li class="chapter" data-level="2.1" data-path="vector-spaces.html"><a href="vector-spaces.html#vector-space"><i class="fa fa-check"></i><b>2.1</b> Vector Space</a><ul>
<li class="chapter" data-level="2.1.1" data-path="vector-spaces.html"><a href="vector-spaces.html#euclidean-space"><i class="fa fa-check"></i><b>2.1.1</b> Euclidean Space</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="vector-spaces.html"><a href="vector-spaces.html#metric-spaces-normed-spaces-inner-product-spaces"><i class="fa fa-check"></i><b>2.2</b> Metric Spaces, Normed Spaces, Inner Product Spaces</a><ul>
<li class="chapter" data-level="2.2.1" data-path="vector-spaces.html"><a href="vector-spaces.html#metric-and-norm"><i class="fa fa-check"></i><b>2.2.1</b> Metric and Norm</a></li>
<li class="chapter" data-level="2.2.2" data-path="vector-spaces.html"><a href="vector-spaces.html#inner-produc-outer-product-cross-product"><i class="fa fa-check"></i><b>2.2.2</b> Inner Produc, Outer Product, Cross Product</a></li>
<li class="chapter" data-level="2.2.3" data-path="vector-spaces.html"><a href="vector-spaces.html#restricted-definition-of-inner-products-in-rn"><i class="fa fa-check"></i><b>2.2.3</b> Restricted Definition of Inner Products in <span class="math inline">\(R^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="vector-spaces.html"><a href="vector-spaces.html#subspaces"><i class="fa fa-check"></i><b>2.3</b> Subspaces</a></li>
<li class="chapter" data-level="2.4" data-path="vector-spaces.html"><a href="vector-spaces.html#fundamental-theorem"><i class="fa fa-check"></i><b>2.4</b> Fundamental Theorem of Linear Algebra</a></li>
<li class="chapter" data-level="2.5" data-path="vector-spaces.html"><a href="vector-spaces.html#rank"><i class="fa fa-check"></i><b>2.5</b> Rank</a><ul>
<li class="chapter" data-level="2.5.1" data-path="vector-spaces.html"><a href="vector-spaces.html#effect-of-operations-on-matrix-rank"><i class="fa fa-check"></i><b>2.5.1</b> Effect of Operations on Matrix Rank</a></li>
<li class="chapter" data-level="2.5.2" data-path="vector-spaces.html"><a href="vector-spaces.html#gram-matrix"><i class="fa fa-check"></i><b>2.5.2</b> Gram Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="vector-spaces.html"><a href="vector-spaces.html#bases-and-coordinate-systems"><i class="fa fa-check"></i><b>2.6</b> Bases and Coordinate Systems</a><ul>
<li class="chapter" data-level="2.6.1" data-path="vector-spaces.html"><a href="vector-spaces.html#change-of-basis"><i class="fa fa-check"></i><b>2.6.1</b> Change of Basis</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="vector-spaces.html"><a href="vector-spaces.html#complexity-of-vector-computations"><i class="fa fa-check"></i><b>2.7</b> Complexity of Vector Computations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="orthogonality.html"><a href="orthogonality.html"><i class="fa fa-check"></i><b>3</b> Orthogonality</a><ul>
<li class="chapter" data-level="3.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-decomposition"><i class="fa fa-check"></i><b>3.1</b> Orthogonal Decomposition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-complements"><i class="fa fa-check"></i><b>3.1.1</b> Orthogonal Complements</a></li>
<li class="chapter" data-level="3.1.2" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-sets-and-orthogonal-basis"><i class="fa fa-check"></i><b>3.1.2</b> Orthogonal Sets and Orthogonal Basis</a></li>
<li class="chapter" data-level="3.1.3" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-decomposition-1"><i class="fa fa-check"></i><b>3.1.3</b> Orthogonal Decomposition</a></li>
<li class="chapter" data-level="3.1.4" data-path="orthogonality.html"><a href="orthogonality.html#best-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Best Approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="orthogonality.html"><a href="orthogonality.html#projection-and-idempotent-matrices"><i class="fa fa-check"></i><b>3.2</b> Projection and idempotent matrices</a></li>
<li class="chapter" data-level="3.3" data-path="orthogonality.html"><a href="orthogonality.html#gram-schmidt-process"><i class="fa fa-check"></i><b>3.3</b> Gram-Schmidt Process</a></li>
<li class="chapter" data-level="3.4" data-path="orthogonality.html"><a href="orthogonality.html#qr-factorizaiton"><i class="fa fa-check"></i><b>3.4</b> QR Factorizaiton</a></li>
<li class="chapter" data-level="3.5" data-path="orthogonality.html"><a href="orthogonality.html#orthonormal-sets-and-orthogonal-matrices"><i class="fa fa-check"></i><b>3.5</b> Orthonormal Sets and Orthogonal Matrices</a><ul>
<li class="chapter" data-level="3.5.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-matrices"><i class="fa fa-check"></i><b>3.5.1</b> Orthogonal Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="orthogonality.html"><a href="orthogonality.html#lesat-squares-problems"><i class="fa fa-check"></i><b>3.6</b> Lesat Squares Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html"><i class="fa fa-check"></i><b>4</b> Eigenthings and Quadratic Forms</a><ul>
<li class="chapter" data-level="4.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>4.1</b> Eigenvectors and Eigenvalues</a><ul>
<li class="chapter" data-level="4.1.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#additional-properties-of-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>4.1.1</b> Additional Properties of Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="4.1.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#left-eigenvectors-and-right-eigenvectors"><i class="fa fa-check"></i><b>4.1.2</b> Left Eigenvectors and Right Eigenvectors</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#diagnolization-and-similar-matrices"><i class="fa fa-check"></i><b>4.2</b> Diagnolization and Similar Matrices</a><ul>
<li class="chapter" data-level="4.2.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#similarity"><i class="fa fa-check"></i><b>4.2.1</b> Similarity</a></li>
<li class="chapter" data-level="4.2.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#jordan-matrix"><i class="fa fa-check"></i><b>4.2.2</b> Jordan Matrix</a></li>
<li class="chapter" data-level="4.2.3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#simultaneous-diagonalization"><i class="fa fa-check"></i><b>4.2.3</b> Simultaneous Diagonalization</a></li>
<li class="chapter" data-level="4.2.4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#cayley-hamilton-theorem"><i class="fa fa-check"></i><b>4.2.4</b> Cayley-Hamilton Theorem</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#symmetric-matrices"><i class="fa fa-check"></i><b>4.3</b> Symmetric Matrices</a><ul>
<li class="chapter" data-level="4.3.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#spectral-decomposition"><i class="fa fa-check"></i><b>4.3.1</b> Spectral Decomposition</a></li>
<li class="chapter" data-level="4.3.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#a-orthogonality"><i class="fa fa-check"></i><b>4.3.2</b> A-Orthogonality</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#quadratic-forms"><i class="fa fa-check"></i><b>4.4</b> Quadratic Forms</a><ul>
<li class="chapter" data-level="4.4.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#change-of-variable"><i class="fa fa-check"></i><b>4.4.1</b> Change of Variable</a></li>
<li class="chapter" data-level="4.4.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#classification-of-quadratic-forms"><i class="fa fa-check"></i><b>4.4.2</b> Classification of Quadratic Forms</a></li>
<li class="chapter" data-level="4.4.3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#gershgorin-discs-and-diagonal-dominance"><i class="fa fa-check"></i><b>4.4.3</b> Gershgorin Discs and Diagonal Dominance</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#cholesky-factorization"><i class="fa fa-check"></i><b>4.5</b> Cholesky Factorization</a></li>
<li class="chapter" data-level="4.6" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#rayleigh-quotients"><i class="fa fa-check"></i><b>4.6</b> Rayleigh Quotients</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html"><i class="fa fa-check"></i><b>5</b> Singular Value Decomposition</a><ul>
<li class="chapter" data-level="5.1" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#singular-values"><i class="fa fa-check"></i><b>5.1</b> Singular Values</a></li>
<li class="chapter" data-level="5.2" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#svd-theorem"><i class="fa fa-check"></i><b>5.2</b> SVD</a></li>
<li class="chapter" data-level="5.3" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#matrix-norms"><i class="fa fa-check"></i><b>5.3</b> Matrix Norms</a><ul>
<li class="chapter" data-level="5.3.1" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#induced-norms"><i class="fa fa-check"></i><b>5.3.1</b> Induced Norms</a></li>
<li class="chapter" data-level="5.3.2" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#entry-wise-norm"><i class="fa fa-check"></i><b>5.3.2</b> Entry-wise Norm</a></li>
<li class="chapter" data-level="5.3.3" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#other-matrix-norms"><i class="fa fa-check"></i><b>5.3.3</b> Other Matrix Norms</a></li>
<li class="chapter" data-level="5.3.4" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#unitary-invariant-norms"><i class="fa fa-check"></i><b>5.3.4</b> Unitary Invariant Norms</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#low-rank-approximation"><i class="fa fa-check"></i><b>5.4</b> Low Rank Approximation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-system.html"><a href="linear-system.html"><i class="fa fa-check"></i><b>6</b> Solutions of Linear System Ax = b</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-system.html"><a href="linear-system.html#generalized-inverse"><i class="fa fa-check"></i><b>6.1</b> Generalized Inverse</a></li>
<li class="chapter" data-level="6.2" data-path="linear-system.html"><a href="linear-system.html#ill-conditioned-matrices"><i class="fa fa-check"></i><b>6.2</b> Ill-Conditioned Matrices</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-system.html"><a href="linear-system.html#condition-number"><i class="fa fa-check"></i><b>6.2.1</b> Condition Number</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Multivariate Calculus</b></span></li>
<li class="chapter" data-level="7" data-path="partial-derivatives.html"><a href="partial-derivatives.html"><i class="fa fa-check"></i><b>7</b> Partial Derivatives</a><ul>
<li class="chapter" data-level="7.1" data-path="partial-derivatives.html"><a href="partial-derivatives.html#limit-and-continuity"><i class="fa fa-check"></i><b>7.1</b> Limit and Continuity</a></li>
<li class="chapter" data-level="7.2" data-path="partial-derivatives.html"><a href="partial-derivatives.html#partial-derivative"><i class="fa fa-check"></i><b>7.2</b> Partial Derivative</a><ul>
<li class="chapter" data-level="7.2.1" data-path="partial-derivatives.html"><a href="partial-derivatives.html#gradient-and-directional-derivative"><i class="fa fa-check"></i><b>7.2.1</b> Gradient and Directional Derivative</a></li>
<li class="chapter" data-level="7.2.2" data-path="partial-derivatives.html"><a href="partial-derivatives.html#linearization-of-two-variable-functions"><i class="fa fa-check"></i><b>7.2.2</b> Linearization of Two-variable Functions</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="partial-derivatives.html"><a href="partial-derivatives.html#differentials"><i class="fa fa-check"></i><b>7.3</b> Differentials</a><ul>
<li class="chapter" data-level="7.3.1" data-path="partial-derivatives.html"><a href="partial-derivatives.html#continuity-partial-derivatives-and-differentiability"><i class="fa fa-check"></i><b>7.3.1</b> Continuity, Partial Derivatives and Differentiability</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="partial-derivatives.html"><a href="partial-derivatives.html#divergence-curl-and-laplacian"><i class="fa fa-check"></i><b>7.4</b> Divergence, Curl, and Laplacian</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="matrix-calculus.html"><a href="matrix-calculus.html"><i class="fa fa-check"></i><b>8</b> Matrix Calculus</a><ul>
<li class="chapter" data-level="8.1" data-path="matrix-calculus.html"><a href="matrix-calculus.html#the-chain-rule"><i class="fa fa-check"></i><b>8.1</b> The Chain Rule</a></li>
<li class="chapter" data-level="8.2" data-path="matrix-calculus.html"><a href="matrix-calculus.html#useful-identities-in-matirx-calculus"><i class="fa fa-check"></i><b>8.2</b> Useful Identities in Matirx Calculus</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="taylor-series.html"><a href="taylor-series.html"><i class="fa fa-check"></i><b>9</b> Taylor Series</a><ul>
<li class="chapter" data-level="9.1" data-path="taylor-series.html"><a href="taylor-series.html#convergence-of-taylor-series"><i class="fa fa-check"></i><b>9.1</b> Convergence of Taylor Series</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="multiple-integral.html"><a href="multiple-integral.html"><i class="fa fa-check"></i><b>10</b> Multiple Integral</a></li>
<li class="part"><span><b>III Probability Theory</b></span></li>
<li class="chapter" data-level="11" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html"><i class="fa fa-check"></i><b>11</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="11.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probabilty-space"><i class="fa fa-check"></i><b>11.1</b> Probabilty Space</a></li>
<li class="chapter" data-level="11.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#counting"><i class="fa fa-check"></i><b>11.2</b> Counting</a></li>
<li class="chapter" data-level="11.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>11.3</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html"><i class="fa fa-check"></i><b>12</b> Random variables and moments</a><ul>
<li class="chapter" data-level="12.1" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#properties-of-expectation-and-variance"><i class="fa fa-check"></i><b>12.1</b> Properties of Expectation and Variance</a><ul>
<li class="chapter" data-level="12.1.1" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#random-vectors"><i class="fa fa-check"></i><b>12.1.1</b> Random vectors</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#other-summaries"><i class="fa fa-check"></i><b>12.2</b> Other Summaries</a></li>
<li class="chapter" data-level="12.3" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#moment-generating-functions"><i class="fa fa-check"></i><b>12.3</b> Moment Generating Functions</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="univariate-distributions.html"><a href="univariate-distributions.html"><i class="fa fa-check"></i><b>13</b> Univariate Distributions</a><ul>
<li class="chapter" data-level="13.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>13.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="13.2" data-path="univariate-distributions.html"><a href="univariate-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>13.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="13.2.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#log-normal-distribution"><i class="fa fa-check"></i><b>13.2.1</b> Log Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="univariate-distributions.html"><a href="univariate-distributions.html#binomial-distribution-and-beta-distribution"><i class="fa fa-check"></i><b>13.3</b> Binomial Distribution and Beta Distribution</a></li>
<li class="chapter" data-level="13.4" data-path="univariate-distributions.html"><a href="univariate-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>13.4</b> Poisson Distribution</a><ul>
<li class="chapter" data-level="13.4.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#poisson-process"><i class="fa fa-check"></i><b>13.4.1</b> Poisson Process</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="univariate-distributions.html"><a href="univariate-distributions.html#exponential-distribution-and-gamma-distribution"><i class="fa fa-check"></i><b>13.5</b> Exponential Distribution and Gamma Distribution</a><ul>
<li class="chapter" data-level="13.5.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#properties"><i class="fa fa-check"></i><b>13.5.1</b> Properties</a></li>
<li class="chapter" data-level="13.5.2" data-path="univariate-distributions.html"><a href="univariate-distributions.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>13.5.2</b> Inverse Gamma Distribution</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="univariate-distributions.html"><a href="univariate-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>13.6</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html"><i class="fa fa-check"></i><b>14</b> Multivariate Distributions</a><ul>
<li class="chapter" data-level="14.1" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>14.1</b> Multivariate Normal Distribution</a><ul>
<li class="chapter" data-level="14.1.1" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html#chi-square-distribution"><i class="fa fa-check"></i><b>14.1.1</b> Chi-square Distribution</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html#dirichlet-distributon"><i class="fa fa-check"></i><b>14.2</b> Dirichlet Distributon</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="markov-chain.html"><a href="markov-chain.html"><i class="fa fa-check"></i><b>15</b> Markov Chain</a></li>
<li class="part"><span><b>IV Learning Theory</b></span></li>
<li class="chapter" data-level="16" data-path="the-learning-problem.html"><a href="the-learning-problem.html"><i class="fa fa-check"></i><b>16</b> The Learning Problem</a></li>
<li class="part"><span><b>V Optimization</b></span></li>
<li class="chapter" data-level="17" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html"><i class="fa fa-check"></i><b>17</b> Basics of Optimization</a><ul>
<li class="chapter" data-level="17.1" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#univariate-optimization"><i class="fa fa-check"></i><b>17.1</b> Univariate Optimization</a></li>
<li class="chapter" data-level="17.2" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#multivariate-optimization"><i class="fa fa-check"></i><b>17.2</b> Multivariate Optimization</a></li>
<li class="chapter" data-level="17.3" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#convex-functions"><i class="fa fa-check"></i><b>17.3</b> Convex Functions</a></li>
<li class="chapter" data-level="17.4" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#method-of-lagrange-multiplier"><i class="fa fa-check"></i><b>17.4</b> Method of Lagrange Multiplier</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="gradient-descent.html"><a href="gradient-descent.html"><i class="fa fa-check"></i><b>18</b> Gradient Descent</a></li>
<li class="part"><span><b>VI Applications</b></span></li>
<li class="chapter" data-level="19" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>19</b> Linear Models</a><ul>
<li class="chapter" data-level="19.1" data-path="linear-models.html"><a href="linear-models.html#ordinary-least-squares"><i class="fa fa-check"></i><b>19.1</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="19.1.1" data-path="linear-models.html"><a href="linear-models.html#least-square-estimation"><i class="fa fa-check"></i><b>19.1.1</b> Least Square Estimation</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="linear-models.html"><a href="linear-models.html#weighted-least-squares"><i class="fa fa-check"></i><b>19.2</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="19.3" data-path="linear-models.html"><a href="linear-models.html#partial-least-squares"><i class="fa fa-check"></i><b>19.3</b> Partial Least Squares</a></li>
<li class="chapter" data-level="19.4" data-path="linear-models.html"><a href="linear-models.html#regularized-regression"><i class="fa fa-check"></i><b>19.4</b> Regularized Regression</a><ul>
<li class="chapter" data-level="19.4.1" data-path="linear-models.html"><a href="linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>19.4.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="19.4.2" data-path="linear-models.html"><a href="linear-models.html#lasso"><i class="fa fa-check"></i><b>19.4.2</b> Lasso</a></li>
<li class="chapter" data-level="19.4.3" data-path="linear-models.html"><a href="linear-models.html#elastic-net"><i class="fa fa-check"></i><b>19.4.3</b> Elastic Net</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>20</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="21" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>21</b> Text Mining</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>
  <a href="https://github.com/rstudio/bookdown" target="blank">Written with bookdown</a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Notes for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-variables-and-moments" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Random variables and moments</h1>
<div id="properties-of-expectation-and-variance" class="section level2">
<h2><span class="header-section-number">12.1</span> Properties of Expectation and Variance</h2>
<p>This section provides some properties of <span class="math inline">\(E(X)\)</span> and <span class="math inline">\(\text{Var}(X)\)</span> commonly-used in probabilistic calculations. Suppose all expectations <span class="math inline">\(E(\cdot)\)</span> exists</p>
<ul>
<li><p><strong>Non-negativity</strong>: If <span class="math inline">\(X \ge 0\)</span> then <span class="math inline">\(E(X) \ge 0\)</span><br />
</p></li>
<li><p><strong>Linearity of expectation</strong></p>
<ul>
<li><span class="math inline">\(E(\alpha X) = \alpha E(X)\)</span> (<span class="math inline">\(\alpha\)</span> is constant)<br />
</li>
<li><span class="math inline">\(E(X + Y) = E(X) + E(Y)\)</span> (<span class="math inline">\(Y\)</span> is also r.v., and <strong>not</strong> necessarily independent of <span class="math inline">\(X\)</span>). More generally, for any r.v. <span class="math inline">\(X_1, ..., X_n\)</span> <span class="math inline">\(E(X_1 + \cdots + X_n) =\sum_{i=1}^n{E(X_i)}\)</span></li>
</ul></li>
<li><p><strong>Monotonicity</strong>: If <span class="math inline">\(X \le Y\)</span>, then <span class="math inline">\(E(X) \le E(Y)\)</span></p></li>
<li><p><strong>Non-multiplicativity</strong>:<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> <span class="math inline">\(E(XY) = E(X)E(Y) + \text{Cov}(X, Y)\)</span>. This means in general <span class="math inline">\(E(XY) \not= E(X)E(Y)\)</span> holds except that <span class="math inline">\(X, Y\)</span> are independent (although this is not a necessary condition)</p></li>
<li><p><strong>law of the unconscious statistician (LOTUS)</strong>. Suppose <span class="math inline">\(g(X)\)</span> is a function of <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is discrete then <span class="math inline">\(E[g(X)] = \sum g(x)f_X(x)\)</span>, and if <span class="math inline">\(X\)</span> is continuous <span class="math inline">\(E[g(X)] = \int g(x)f(x)dx\)</span></p></li>
<li><p><span class="math inline">\(E(X^2) = \text{Var}(X) + [E(X)]^2\)</span><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p></li>
</ul>
<p>An important extension of the previous identity is used listed in the following lemma.</p>

<div class="lemma">
<p><span id="lem:mean-square-expectation" class="lemma"><strong>Lemma 12.1  </strong></span>
The fact that <span class="math inline">\(\text{E}(X^2) = \text{Var}(X) + \mu^2\)</span> is a special case of the following identity</p>
<p><span class="math display">\[
E(X  - c)^2 = \text{Var}(X) + (\mu - c)^2
\]</span></p>
where <span class="math inline">\(c = 0\)</span>
</div>


<div class="proof">
Proof
</div>

<p>Use the fact that variance is not affected when adding a constant</p>
<p><span class="math display">\[
\begin{split}
\text{Var}(X) &amp;= \text{Var}(X - c) \\
&amp;= E(X - c)^2 - (E(X - c))^2 \\ 
&amp;= E(X - c)^2 - (\mu - c)^2
\end{split}
\]</span></p>
<hr>
<p>For <span class="math inline">\(\text{Var}(X)\)</span>, we have the following properties</p>
<ul>
<li><p><strong>non-negative</strong>: <span class="math inline">\(\text{Var}(X) \ge 0\)</span> with equality only if <span class="math inline">\(X\)</span> follows degenerate distribution<br />
</p></li>
<li><p><strong>invariant to adding constant</strong>: <span class="math inline">\(\text{Var}(X + \alpha) = \text{Var}(X)\)</span></p></li>
<li><p>If all values are scaled by a constant, the variance is scaled by the square of that constant: <span class="math inline">\(\text{Var}(\alpha X) = \alpha^2\text{Var}(X)\)</span></p></li>
<li><p>The variance of a sum of two random variables is given by</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(aX + bY) &amp;= a^2\text{Var}(X) + b^2\text{Var}(Y) + 2ab \cdot\text{Cov}(X, Y) \\
\text{Var}(aX - bY) &amp;= a^2\text{Var}(X) + b^2\text{Var}(Y) - 2ab \cdot\text{Cov}(X, Y)
\end{aligned}
\]</span>
By extension, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are uncorrelated, <span class="math inline">\(\text{Var}(aX + bY) = a^2\text{Var}(X) + b^2\text{Var}(Y)\)</span></p>
<ul>
<li><strong>variance-covariance operations</strong>: the variance of a linear combination of r.v. is the sum of variance plus all pairs of covariances</li>
</ul>
<p><span class="math display">\[
\text{Var}(\sum_{i=1}^{n} \alpha_i X_i) =
\sum_{i=1}^{n} \alpha^2 \text{Var}(X_i) + \sum_{i \not = j}a_ia_j \text{Cov}(X_i, X_j)
\]</span></p>
<div id="random-vectors" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Random vectors</h3>
</div>
</div>
<div id="other-summaries" class="section level2">
<h2><span class="header-section-number">12.2</span> Other Summaries</h2>

<div class="theorem">
<p><span id="thm:unnamed-chunk-2" class="theorem"><strong>Theorem 3.2  </strong></span>Let <span class="math inline">\(X\)</span> be an r.v. with expectation <span class="math inline">\(E(X) = \mu\)</span>, and let <span class="math inline">\(m\)</span> be the median of <span class="math inline">\(X\)</span></p>
<ul>
<li><p>The value of <span class="math inline">\(c\)</span> that minimizes the mean squared error <span class="math inline">\(E(X - c)^2\)</span> is <span class="math inline">\(c = \mu\)</span></p></li>
<li><p>The value of <span class="math inline">\(c\)</span> that minimizes the mean absolute error <span class="math inline">\(E |X - c|\)</span> is <span class="math inline">\(c = m\)</span></p>
</div></li>
</ul>

<div class="proof">
Proof
</div>

<p>In the case of mean squared error, we have <span class="math inline">\(E(X - c)^2 = \text{Var}(X) + (\mu - c)^2\)</span> according to lemma <a href="random-variables-and-moments.html#lem:mean-square-expectation">12.1</a>. Therefore, the quantity is minimized when <span class="math inline">\(c = \mu\)</span>.</p>
<p>As for the mean absolute error, we need to show that <span class="math inline">\(E|X - m| \le E |X - a|\)</span> for any <span class="math inline">\(a\)</span>, which is equivalent to <span class="math inline">\(E(|X - a| - |X - m|) \ge 0\)</span>. Assume <span class="math inline">\(m &lt; a\)</span> without loss of generality, if <span class="math inline">\(X \le m\)</span> then</p>
<p><span class="math display">\[
|X - a| -|X - m| = a-m
\]</span></p>
<p>and if <span class="math inline">\(X &gt; m\)</span></p>
<p><span class="math display">\[
|X - a| - |X - m| \ge X - a - (X- m) = m -a
\]</span></p>
<p>Let</p>
<p><span class="math display">\[
Y  = |X - a| - |X - m|
\]</span></p>
<p>When can split <span class="math inline">\(E(Y)\)</span> into two parts based on whether the event <span class="math inline">\(X \le m\)</span> occurs</p>
<p><span class="math display">\[
\begin{split}
E(Y) &amp;= E(Y | X \le m)P(X \le m) +E(Y | X &gt; m)P(X \gt m) \\
&amp;\ge (a - m)P(X \le m) + (m - a)P(X &gt; m) \\
&amp;= (a-m)P(X \le m) - (a - m)(1 - P(X \le m)) \\
&amp;= (a - m)(2P(X \le m) - 1)
\end{split}
\]</span>
Since for median <span class="math inline">\(m\)</span> we know <span class="math inline">\(P(X \le m) \le \frac{1}{2}\)</span>, we get <span class="math inline">\(E(Y) \ge 0\)</span> with equality when <span class="math inline">\(a = m\)</span>. This means the mean absolute error <span class="math inline">\(E|X - a|\)</span> is minimized when <span class="math inline">\(a\)</span> is the median of <span class="math inline">\(X\)</span>.</p>
</div>
<div id="moment-generating-functions" class="section level2">
<h2><span class="header-section-number">12.3</span> Moment Generating Functions</h2>

<div class="theorem">
<p><span id="thm:mgf-moment" class="theorem"><strong>Theorem 12.1  (Moments via derivaties of MGF)  </strong></span>The <span class="math inline">\(n\)</span>th momment of r.v. <span class="math inline">\(X\)</span> is the <span class="math inline">\(n\)</span>th derivative of its MGF evaluated at zero</p>
<span class="math display">\[
E(X^n) = M^{n}(0)
\]</span>
</div>


<div class="proof">
Proof
</div>

<p>The Taylor expansion of <span class="math inline">\(M(t)\)</span> about <span class="math inline">\(0\)</span> is</p>
<p><span class="math display">\[
M(t) = \sum_{n=1}^{\infty} M^{(n)}(0) \frac{t^n}{n!}
\]</span></p>
<p>On the other hand, use the fact that the Taylor expansion of <span class="math inline">\(e^x\)</span> about <span class="math inline">\(0\)</span> is <span class="math inline">\(\sum \frac{x^n}{n!}\)</span>, we have</p>
<p><span class="math display">\[
\begin{split}
M(t)  &amp;= E(e^{tX}) \\
&amp;= E(\sum_{n = 0}^{\infty} \frac{X^nt^n}{n!}) \\
&amp;= \sum_{n = 0}^{\infty} E(X^n)\frac{t^n}{n!} \qquad \text{due to techinical conditions of MGF}\\ 
\end{split} 
\]</span></p>
<p>Matching the coefficients of the two expansions, we get <span class="math inline">\(E(X^n) = M^{(n)}(0)\)</span></p>
<p>Note that expectation of infinite sum <span class="math inline">\(E(\sum_{i = 0}^{\infty}X_i)\)</span> may not be equal to <span class="math inline">\(\sum_{n=0}^{\infty}E(X_I)\)</span>. In other words, linearity of expectation may not hold for infinite sums. However, the definition of MGF has a technical condition â€“ MGF is finite on some open interval <span class="math inline">\((-a, a)\)</span> containing <span class="math inline">\(0\)</span> â€“ which ensures the linearity property used in the following formula.</p>

<div class="theorem">
<span id="thm:mgf-distribution" class="theorem"><strong>Theorem 12.2  (One-to-one relationship between MGF and distribution)  </strong></span>The MGF of a random variable determines its distribution. If two random variables have the same MGF, then they follow the same distribution.
</div>


<div class="theorem">
<p><span id="thm:mgf-convolution" class="theorem"><strong>Theorem 12.3  (MGF and convolutions)  </strong></span>The MGF of the convolution (sum) of two independent r.v. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is the product of the individual MGFs. This is because</p>
</div>

<p><span class="math display">\[
\begin{split}
M_{X + Y}(t) &amp;= E(e^{t(X + Y)}) \\
&amp;= E(e^{tX} \cdot e^{tY})\\
&amp;= E(e^{tX}) \cdot E(e^{tY}) \qquad \text{X and Y are independent}\\
&amp;= M_X(t) \cdot M_Y(t)
\end{split}
\]</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Proof: <span class="math inline">\(E(XY) = E(X)E(Y) + \text{Cov}(X, Y)\)</span>. Start with covariance <span class="math display">\[\begin{split}
\text{Cov}(X, Y) &amp;= E[(X - \mu_x)(Y - \mu_y)] \\
&amp;= E(XY - X\mu_y - Y\mu_x + \mu_x\mu_y) \\
&amp;= E(XY) - \mu_yE(X) - \mu_xE(Y) + \mu_x\mu_y \\
&amp;= E(XY) - 2\mu_x\mu_y + \mu_x\mu_y \\
&amp; = E(XY) - \mu_x\mu_y
\end{split}\]</span><a href="random-variables-and-moments.html#fnref3" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn4"><p>Proof: <span class="math inline">\(E(X^2) = \text{Var}(X) + \big( E(X) \big)\)</span>. <span class="math display">\[
\begin{split}
E(X^2) &amp;= E \big[ (X \pm \mu)^2 \big] \\
&amp;= E(X - \mu)^2 + \mu^2 + 2 \mu E(X -\mu) \qquad \text{the 3rd term is zero} \\
&amp;= \text{Var}(X) + [E(X)]^2
\end{split}
\]</span><a href="random-variables-and-moments.html#fnref4" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics-of-probability-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="univariate-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/math-foundations/edit/master/moments.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Random variables and moments | Mathematical Notes for Machine Learning</title>
  <meta name="description" content="Chapter 11 Random variables and moments | Mathematical Notes for Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Random variables and moments | Mathematical Notes for Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="enixam/math-foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Random variables and moments | Mathematical Notes for Machine Learning" />
  
  
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-08-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability-basics.html"/>
<link rel="next" href="univariate-distributions.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math Notes for Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Linear Algebra</b></span></li>
<li class="chapter" data-level="1" data-path="matrix-basics.html"><a href="matrix-basics.html"><i class="fa fa-check"></i><b>1</b> Matrix basics</a><ul>
<li class="chapter" data-level="1.1" data-path="matrix-basics.html"><a href="matrix-basics.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.1</b> Matrix multiplication</a></li>
<li class="chapter" data-level="1.2" data-path="matrix-basics.html"><a href="matrix-basics.html#elemetary-matrix-and-row-operations"><i class="fa fa-check"></i><b>1.2</b> Elemetary matrix and row operations</a></li>
<li class="chapter" data-level="1.3" data-path="matrix-basics.html"><a href="matrix-basics.html#lu-factorization"><i class="fa fa-check"></i><b>1.3</b> LU factorization</a></li>
<li class="chapter" data-level="1.4" data-path="matrix-basics.html"><a href="matrix-basics.html#determinants"><i class="fa fa-check"></i><b>1.4</b> Determinants</a><ul>
<li class="chapter" data-level="1.4.1" data-path="matrix-basics.html"><a href="matrix-basics.html#cofactor-expansion"><i class="fa fa-check"></i><b>1.4.1</b> Cofactor expansion</a></li>
<li class="chapter" data-level="1.4.2" data-path="matrix-basics.html"><a href="matrix-basics.html#geometric-interpretation-of-determinant"><i class="fa fa-check"></i><b>1.4.2</b> Geometric interpretation of determinant</a></li>
<li class="chapter" data-level="1.4.3" data-path="matrix-basics.html"><a href="matrix-basics.html#properties-of-determinant"><i class="fa fa-check"></i><b>1.4.3</b> Properties of determinant</a></li>
<li class="chapter" data-level="1.4.4" data-path="matrix-basics.html"><a href="matrix-basics.html#cramers-rule"><i class="fa fa-check"></i><b>1.4.4</b> Cramerâ€™s rule</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="matrix-basics.html"><a href="matrix-basics.html#trace"><i class="fa fa-check"></i><b>1.5</b> Trace</a></li>
<li class="chapter" data-level="1.6" data-path="matrix-basics.html"><a href="matrix-basics.html#matrix-inversion"><i class="fa fa-check"></i><b>1.6</b> Matrix inversion</a><ul>
<li class="chapter" data-level="1.6.1" data-path="matrix-basics.html"><a href="matrix-basics.html#the-matrix-inversion-lemma"><i class="fa fa-check"></i><b>1.6.1</b> The matrix inversion lemma</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="matrix-basics.html"><a href="matrix-basics.html#matrix-multiplication-as-linear-transformation"><i class="fa fa-check"></i><b>1.7</b> Matrix multiplication as linear transformation</a><ul>
<li class="chapter" data-level="1.7.1" data-path="matrix-basics.html"><a href="matrix-basics.html#matrix-multiplication-as-geometric-operators"><i class="fa fa-check"></i><b>1.7.1</b> Matrix multiplication as geometric operators</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="matrix-basics.html"><a href="matrix-basics.html#statistics-and-proabability"><i class="fa fa-check"></i><b>1.8</b> Statistics and proabability</a><ul>
<li class="chapter" data-level="1.8.1" data-path="matrix-basics.html"><a href="matrix-basics.html#sample-statistics"><i class="fa fa-check"></i><b>1.8.1</b> Sample statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="vector-spaces.html"><a href="vector-spaces.html"><i class="fa fa-check"></i><b>2</b> Vector spaces</a><ul>
<li class="chapter" data-level="2.1" data-path="vector-spaces.html"><a href="vector-spaces.html#vector-space"><i class="fa fa-check"></i><b>2.1</b> Vector space</a><ul>
<li class="chapter" data-level="2.1.1" data-path="vector-spaces.html"><a href="vector-spaces.html#euclidean-space"><i class="fa fa-check"></i><b>2.1.1</b> Euclidean space</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="vector-spaces.html"><a href="vector-spaces.html#metric-spaces-normed-spaces-inner-product-spaces"><i class="fa fa-check"></i><b>2.2</b> Metric spaces, normed spaces, inner product spaces</a><ul>
<li class="chapter" data-level="2.2.1" data-path="vector-spaces.html"><a href="vector-spaces.html#restricted-definition-of-inner-products-in-rn"><i class="fa fa-check"></i><b>2.2.1</b> Restricted definition of inner products in <span class="math inline">\(R^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="vector-spaces.html"><a href="vector-spaces.html#subspaces"><i class="fa fa-check"></i><b>2.3</b> Subspaces</a></li>
<li class="chapter" data-level="2.4" data-path="vector-spaces.html"><a href="vector-spaces.html#fundamental-theorem"><i class="fa fa-check"></i><b>2.4</b> Fundamental theorem of linear algebra</a></li>
<li class="chapter" data-level="2.5" data-path="vector-spaces.html"><a href="vector-spaces.html#rank"><i class="fa fa-check"></i><b>2.5</b> Rank</a><ul>
<li class="chapter" data-level="2.5.1" data-path="vector-spaces.html"><a href="vector-spaces.html#effect-of-operations-on-matrix-rank"><i class="fa fa-check"></i><b>2.5.1</b> Effect of operations on matrix rank</a></li>
<li class="chapter" data-level="2.5.2" data-path="vector-spaces.html"><a href="vector-spaces.html#gram-matrix"><i class="fa fa-check"></i><b>2.5.2</b> Gram matrix</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="orthogonality.html"><a href="orthogonality.html"><i class="fa fa-check"></i><b>3</b> Orthogonality</a><ul>
<li class="chapter" data-level="3.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-decomposition"><i class="fa fa-check"></i><b>3.1</b> Orthogonal decomposition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-complements"><i class="fa fa-check"></i><b>3.1.1</b> Orthogonal complements</a></li>
<li class="chapter" data-level="3.1.2" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-sets-and-orthogonal-basis"><i class="fa fa-check"></i><b>3.1.2</b> Orthogonal sets and orthogonal basis</a></li>
<li class="chapter" data-level="3.1.3" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-decomposition-1"><i class="fa fa-check"></i><b>3.1.3</b> Orthogonal decomposition</a></li>
<li class="chapter" data-level="3.1.4" data-path="orthogonality.html"><a href="orthogonality.html#best-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Best approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="orthogonality.html"><a href="orthogonality.html#idempotent-and-projection-matrices"><i class="fa fa-check"></i><b>3.2</b> Idempotent and Projection Matrices</a></li>
<li class="chapter" data-level="3.3" data-path="orthogonality.html"><a href="orthogonality.html#gram-schmidt-process"><i class="fa fa-check"></i><b>3.3</b> Gram-Schmidt process</a><ul>
<li class="chapter" data-level="3.3.1" data-path="orthogonality.html"><a href="orthogonality.html#qr-factorizaiton"><i class="fa fa-check"></i><b>3.3.1</b> QR factorizaiton</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="orthogonality.html"><a href="orthogonality.html#orthonormal-sets-and-orthogonal-matrices"><i class="fa fa-check"></i><b>3.4</b> Orthonormal sets and orthogonal matrices</a><ul>
<li class="chapter" data-level="3.4.1" data-path="orthogonality.html"><a href="orthogonality.html#orthogonal-matrices"><i class="fa fa-check"></i><b>3.4.1</b> Orthogonal matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="orthogonality.html"><a href="orthogonality.html#lesat-squares-problems"><i class="fa fa-check"></i><b>3.5</b> Lesat squares problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html"><i class="fa fa-check"></i><b>4</b> Eigenthings and quadratic forms</a><ul>
<li class="chapter" data-level="4.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>4.1</b> Eigenvectors and eigenvalues</a><ul>
<li class="chapter" data-level="4.1.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#additional-properties-of-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>4.1.1</b> Additional properties of eigenvalues and eigenvectors</a></li>
<li class="chapter" data-level="4.1.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#left-eigenvectors-and-right-eigenvectors"><i class="fa fa-check"></i><b>4.1.2</b> Left eigenvectors and right eigenvectors</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#diagnolization-and-similar-matrices"><i class="fa fa-check"></i><b>4.2</b> Diagnolization and similar matrices</a><ul>
<li class="chapter" data-level="4.2.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#similarity"><i class="fa fa-check"></i><b>4.2.1</b> Similarity</a></li>
<li class="chapter" data-level="4.2.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#jordan-matrix"><i class="fa fa-check"></i><b>4.2.2</b> Jordan matrix</a></li>
<li class="chapter" data-level="4.2.3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#simultaneous-diagonalization"><i class="fa fa-check"></i><b>4.2.3</b> Simultaneous Diagonalization</a></li>
<li class="chapter" data-level="4.2.4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#cayley-hamilton-theorem"><i class="fa fa-check"></i><b>4.2.4</b> Cayley-Hamilton theorem</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#symmetric-matrices"><i class="fa fa-check"></i><b>4.3</b> Symmetric matrices</a><ul>
<li class="chapter" data-level="4.3.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#spectral-decomposition"><i class="fa fa-check"></i><b>4.3.1</b> Spectral decomposition</a></li>
<li class="chapter" data-level="4.3.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#a-rrthogonality"><i class="fa fa-check"></i><b>4.3.2</b> A-Rrthogonality</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#quadratic-forms"><i class="fa fa-check"></i><b>4.4</b> Quadratic forms</a><ul>
<li class="chapter" data-level="4.4.1" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#change-of-variabele"><i class="fa fa-check"></i><b>4.4.1</b> Change of variabele</a></li>
<li class="chapter" data-level="4.4.2" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#classification-of-quadratic-forms"><i class="fa fa-check"></i><b>4.4.2</b> Classification of quadratic forms</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#cholesky-factorization"><i class="fa fa-check"></i><b>4.5</b> Cholesky factorization</a></li>
<li class="chapter" data-level="4.6" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html#rayleigh-quotients"><i class="fa fa-check"></i><b>4.6</b> Rayleigh quotients</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html"><i class="fa fa-check"></i><b>5</b> Singular value decomposition</a><ul>
<li class="chapter" data-level="5.1" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#singular-values-of-m-x-n-matrix"><i class="fa fa-check"></i><b>5.1</b> Singular values of m x n matrix</a></li>
<li class="chapter" data-level="5.2" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#svd-theorem"><i class="fa fa-check"></i><b>5.2</b> The singular value decomposition</a></li>
<li class="chapter" data-level="5.3" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#matrix-norms"><i class="fa fa-check"></i><b>5.3</b> Matrix norms</a><ul>
<li class="chapter" data-level="5.3.1" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#induced-norms"><i class="fa fa-check"></i><b>5.3.1</b> Induced norms</a></li>
<li class="chapter" data-level="5.3.2" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#entry-wise-norm"><i class="fa fa-check"></i><b>5.3.2</b> Entry-wise norm</a></li>
<li class="chapter" data-level="5.3.3" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#other-matrix-norms"><i class="fa fa-check"></i><b>5.3.3</b> Other matrix norms</a></li>
<li class="chapter" data-level="5.3.4" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#unitary-invariant-norms"><i class="fa fa-check"></i><b>5.3.4</b> Unitary invariant norms</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="singular-value-decomposition.html"><a href="singular-value-decomposition.html#low-rank-approximation"><i class="fa fa-check"></i><b>5.4</b> Low rank approximation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="solutions-of-linear-system-ax-b.html"><a href="solutions-of-linear-system-ax-b.html"><i class="fa fa-check"></i><b>6</b> Solutions of linear system Ax = b</a><ul>
<li class="chapter" data-level="6.1" data-path="solutions-of-linear-system-ax-b.html"><a href="solutions-of-linear-system-ax-b.html#generalized-inverse"><i class="fa fa-check"></i><b>6.1</b> Generalized inverse</a></li>
<li class="chapter" data-level="6.2" data-path="solutions-of-linear-system-ax-b.html"><a href="solutions-of-linear-system-ax-b.html#ill-conditioned-matrices"><i class="fa fa-check"></i><b>6.2</b> Ill-conditioned matrices</a><ul>
<li class="chapter" data-level="6.2.1" data-path="solutions-of-linear-system-ax-b.html"><a href="solutions-of-linear-system-ax-b.html#the-condition-number"><i class="fa fa-check"></i><b>6.2.1</b> The condition number</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Calculus</b></span></li>
<li class="chapter" data-level="7" data-path="taylor-series-and-expansion.html"><a href="taylor-series-and-expansion.html"><i class="fa fa-check"></i><b>7</b> Taylor series and expansion</a></li>
<li class="chapter" data-level="8" data-path="matrix-calculus.html"><a href="matrix-calculus.html"><i class="fa fa-check"></i><b>8</b> Matrix calculus</a><ul>
<li class="chapter" data-level="8.1" data-path="matrix-calculus.html"><a href="matrix-calculus.html#the-chain-rule"><i class="fa fa-check"></i><b>8.1</b> The chain rule</a></li>
<li class="chapter" data-level="8.2" data-path="matrix-calculus.html"><a href="matrix-calculus.html#useful-identities-in-matirx-calculus"><i class="fa fa-check"></i><b>8.2</b> Useful identities in matirx calculus</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="infinite-sequences-and-series.html"><a href="infinite-sequences-and-series.html"><i class="fa fa-check"></i><b>9</b> Infinite sequences and series</a></li>
<li class="part"><span><b>III Probability Theory</b></span></li>
<li class="chapter" data-level="10" data-path="probability-basics.html"><a href="probability-basics.html"><i class="fa fa-check"></i><b>10</b> Probability basics</a><ul>
<li class="chapter" data-level="10.1" data-path="probability-basics.html"><a href="probability-basics.html#probabilty-space"><i class="fa fa-check"></i><b>10.1</b> Probabilty space</a></li>
<li class="chapter" data-level="10.2" data-path="probability-basics.html"><a href="probability-basics.html#counting"><i class="fa fa-check"></i><b>10.2</b> Counting</a></li>
<li class="chapter" data-level="10.3" data-path="probability-basics.html"><a href="probability-basics.html#conditional-probability"><i class="fa fa-check"></i><b>10.3</b> Conditional probability</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html"><i class="fa fa-check"></i><b>11</b> Random variables and moments</a><ul>
<li class="chapter" data-level="11.1" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#properties-of-expectation-and-variance"><i class="fa fa-check"></i><b>11.1</b> Properties of expectation and variance</a></li>
<li class="chapter" data-level="11.2" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#other-summaries-of-distribution-of-random-variables"><i class="fa fa-check"></i><b>11.2</b> Other summaries of distribution of random variables</a></li>
<li class="chapter" data-level="11.3" data-path="random-variables-and-moments.html"><a href="random-variables-and-moments.html#moment-generating-functions"><i class="fa fa-check"></i><b>11.3</b> Moment generating functions</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="univariate-distributions.html"><a href="univariate-distributions.html"><i class="fa fa-check"></i><b>12</b> Univariate distributions</a><ul>
<li class="chapter" data-level="12.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>12.1</b> Uniform distribution</a></li>
<li class="chapter" data-level="12.2" data-path="univariate-distributions.html"><a href="univariate-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>12.2</b> Normal distribution</a><ul>
<li class="chapter" data-level="12.2.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#log-normal-distribution"><i class="fa fa-check"></i><b>12.2.1</b> Log normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="univariate-distributions.html"><a href="univariate-distributions.html#binomial-distribution-and-beta-distribution"><i class="fa fa-check"></i><b>12.3</b> Binomial distribution and Beta distribution</a></li>
<li class="chapter" data-level="12.4" data-path="univariate-distributions.html"><a href="univariate-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>12.4</b> Poisson distribution</a><ul>
<li class="chapter" data-level="12.4.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#poisson-process"><i class="fa fa-check"></i><b>12.4.1</b> Poisson process</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="univariate-distributions.html"><a href="univariate-distributions.html#exponential-distribution-and-gamma-distribution"><i class="fa fa-check"></i><b>12.5</b> Exponential distribution and Gamma distribution</a><ul>
<li class="chapter" data-level="12.5.1" data-path="univariate-distributions.html"><a href="univariate-distributions.html#properties"><i class="fa fa-check"></i><b>12.5.1</b> Properties</a></li>
<li class="chapter" data-level="12.5.2" data-path="univariate-distributions.html"><a href="univariate-distributions.html#inverse-gamma-distribution"><i class="fa fa-check"></i><b>12.5.2</b> Inverse Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="univariate-distributions.html"><a href="univariate-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>12.6</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html"><i class="fa fa-check"></i><b>13</b> Multivariate distributions</a><ul>
<li class="chapter" data-level="13.1" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>13.1</b> Multivariate normal distribution</a></li>
<li class="chapter" data-level="13.2" data-path="multivariate-distributions.html"><a href="multivariate-distributions.html#dirichlet-distributon"><i class="fa fa-check"></i><b>13.2</b> Dirichlet distributon</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="markov-chain.html"><a href="markov-chain.html"><i class="fa fa-check"></i><b>14</b> Markov Chain</a></li>
<li class="part"><span><b>IV Optimization</b></span></li>
<li class="chapter" data-level="15" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html"><i class="fa fa-check"></i><b>15</b> Basics of optimization</a><ul>
<li class="chapter" data-level="15.1" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#univariate-optimization"><i class="fa fa-check"></i><b>15.1</b> Univariate optimization</a></li>
<li class="chapter" data-level="15.2" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#multivariate-optimization"><i class="fa fa-check"></i><b>15.2</b> Multivariate optimization</a></li>
<li class="chapter" data-level="15.3" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#convex-functions"><i class="fa fa-check"></i><b>15.3</b> Convex functions</a></li>
<li class="chapter" data-level="15.4" data-path="basics-of-optimization.html"><a href="basics-of-optimization.html#lagrange-multipliers"><i class="fa fa-check"></i><b>15.4</b> Lagrange multipliers</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="gradient-descent.html"><a href="gradient-descent.html"><i class="fa fa-check"></i><b>16</b> Gradient descent</a></li>
<li class="part"><span><b>V Applications</b></span></li>
<li class="chapter" data-level="17" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>17</b> Linear models</a><ul>
<li class="chapter" data-level="17.1" data-path="linear-models.html"><a href="linear-models.html#ordinary-least-squares"><i class="fa fa-check"></i><b>17.1</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="17.1.1" data-path="linear-models.html"><a href="linear-models.html#least-square-estimation"><i class="fa fa-check"></i><b>17.1.1</b> Least square estimation</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="linear-models.html"><a href="linear-models.html#weighted-least-squares"><i class="fa fa-check"></i><b>17.2</b> Weighted least squares</a></li>
<li class="chapter" data-level="17.3" data-path="linear-models.html"><a href="linear-models.html#partial-least-squres"><i class="fa fa-check"></i><b>17.3</b> Partial least squres</a></li>
<li class="chapter" data-level="17.4" data-path="linear-models.html"><a href="linear-models.html#regularized-regression"><i class="fa fa-check"></i><b>17.4</b> Regularized regression</a><ul>
<li class="chapter" data-level="17.4.1" data-path="linear-models.html"><a href="linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>17.4.1</b> Ridge regression</a></li>
<li class="chapter" data-level="17.4.2" data-path="linear-models.html"><a href="linear-models.html#lasso-regression"><i class="fa fa-check"></i><b>17.4.2</b> Lasso regression</a></li>
<li class="chapter" data-level="17.4.3" data-path="linear-models.html"><a href="linear-models.html#elastic-net-regression"><i class="fa fa-check"></i><b>17.4.3</b> Elastic net regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>18</b> Principal component analysis</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>
  <a href="https://github.com/rstudio/bookdown" target="blank">Written with bookdown</a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Notes for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-variables-and-moments" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Random variables and moments</h1>
<div id="properties-of-expectation-and-variance" class="section level2">
<h2><span class="header-section-number">11.1</span> Properties of expectation and variance</h2>
<p>This section provides some properties of <span class="math inline">\(E(X)\)</span> and <span class="math inline">\(\text{Var}(X)\)</span> commonly-used in probabilistic calculations. Suppose all expectations <span class="math inline">\(E(\cdot)\)</span> exists</p>
<ul>
<li><p><strong>Non-negativity</strong>: If <span class="math inline">\(X \ge 0\)</span> then <span class="math inline">\(E(X) \ge 0\)</span><br />
</p></li>
<li><p><strong>Linearity of expectation</strong></p>
<ul>
<li><span class="math inline">\(E(\alpha X) = \alpha E(X)\)</span> (<span class="math inline">\(\alpha\)</span> is constant)<br />
</li>
<li><span class="math inline">\(E(X + Y) = E(X) + E(Y)\)</span> (<span class="math inline">\(Y\)</span> is also r.v., and <strong>not</strong> necessarily independent of <span class="math inline">\(X\)</span>). More generally, for any r.v. <span class="math inline">\(X_1, ..., X_n\)</span> <span class="math inline">\(E(X_1 + \cdots + X_n) =\sum_{i=1}^n{E(X_i)}\)</span></li>
</ul></li>
<li><p><strong>Monotonicity</strong>: If <span class="math inline">\(X \le Y\)</span>, then <span class="math inline">\(E(X) \le E(Y)\)</span></p></li>
<li><p><strong>Non-multiplicativity</strong>:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> <span class="math inline">\(E(XY) = E(X)E(Y) + \text{Cov}(X, Y)\)</span>. This means in general <span class="math inline">\(E(XY) \not= E(X)E(Y)\)</span> holds except that <span class="math inline">\(X, Y\)</span> are independent (although this is not a necessary condition)</p></li>
<li><p><strong>law of the unconscious statistician (LOTUS)</strong>. Suppose <span class="math inline">\(g(X)\)</span> is a function of <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is discrete then <span class="math inline">\(E[g(X)] = \sum g(x)f_X(x)\)</span>, and if <span class="math inline">\(X\)</span> is continuous <span class="math inline">\(E[g(X)] = \int g(x)f(x)dx\)</span></p></li>
<li><p><span class="math inline">\(E(X^2) = \text{Var}(X) + [E(X)]^2\)</span><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p></li>
</ul>
<p>An important extension of the previous identity is used listed in the following lemma.</p>

<div class="lemma">
<p><span id="lem:mean-square-expectation" class="lemma"><strong>Lemma 11.1  </strong></span>
The fact that <span class="math inline">\(\text{E}(X^2) = \text{Var}(X) + \mu^2\)</span> is a special case of the following identity</p>
<p><span class="math display">\[
E(X  - c)^2 = \text{Var}(X) + (\mu - c)^2
\]</span></p>
where <span class="math inline">\(c = 0\)</span>
</div>


<div class="proof">
Proof
</div>

<p>Use the fact that variance is not affected when adding a constant</p>
<p><span class="math display">\[
\begin{split}
\text{Var}(X) &amp;= \text{Var}(X - c) \\
&amp;= E(X - c)^2 - (E(X - c))^2 \\ 
&amp;= E(X - c)^2 - (\mu - c)^2
\end{split}
\]</span></p>
<hr>
<p>For <span class="math inline">\(\text{Var}(X)\)</span>, we have the following properties</p>
<ul>
<li><p><strong>non-negative</strong>: <span class="math inline">\(\text{Var}(X) \ge 0\)</span> with equality only if <span class="math inline">\(X\)</span> follows degenerate distribution<br />
</p></li>
<li><p><strong>invariant to adding constant</strong>: <span class="math inline">\(\text{Var}(X + \alpha) = \text{Var}(X)\)</span></p></li>
<li><p>If all values are scaled by a constant, the variance is scaled by the square of that constant: <span class="math inline">\(\text{Var}(\alpha X) = \alpha^2\text{Var}(X)\)</span></p></li>
<li><p>The variance of a sum of two random variables is given by</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(aX + bY) &amp;= a^2\text{Var}(X) + b^2\text{Var}(Y) + 2ab \cdot\text{Cov}(X, Y) \\
\text{Var}(aX - bY) &amp;= a^2\text{Var}(X) + b^2\text{Var}(Y) - 2ab \cdot\text{Cov}(X, Y)
\end{aligned}
\]</span>
By extension, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are uncorrelated, <span class="math inline">\(\text{Var}(aX + bY) = a^2\text{Var}(X) + b^2\text{Var}(Y)\)</span></p>
<ul>
<li><strong>variance-covariance operations</strong>: the variance of a linear combination of r.v. is the sum of variance plus all pairs of covariances</li>
</ul>
<p><span class="math display">\[
\text{Var}(\sum_{i=1}^{n} \alpha_i X_i) =
\sum_{i=1}^{n} \alpha^2 \text{Var}(X_i) + \sum_{i \not = j}a_ia_j \text{Cov}(X_i, X_j)
\]</span></p>
</div>
<div id="other-summaries-of-distribution-of-random-variables" class="section level2">
<h2><span class="header-section-number">11.2</span> Other summaries of distribution of random variables</h2>

<div class="theorem">
<p><span id="thm:unnamed-chunk-2" class="theorem"><strong>Theorem 3.1  </strong></span>Let <span class="math inline">\(X\)</span> be an r.v. with expectation <span class="math inline">\(E(X) = \mu\)</span>, and let <span class="math inline">\(m\)</span> be the median of <span class="math inline">\(X\)</span></p>
<ul>
<li><p>The value of <span class="math inline">\(c\)</span> that minimizes the mean squared error <span class="math inline">\(E(X - c)^2\)</span> is <span class="math inline">\(c = \mu\)</span></p></li>
<li><p>The value of <span class="math inline">\(c\)</span> that minimizes the mean absolute error <span class="math inline">\(E |X - c|\)</span> is <span class="math inline">\(c = m\)</span></p>
</div></li>
</ul>

<div class="proof">
Proof
</div>

<p>In the case of mean squared error, we have <span class="math inline">\(E(X - c)^2 = \text{Var}(X) + (\mu - c)^2\)</span> according to lemma <a href="random-variables-and-moments.html#lem:mean-square-expectation">11.1</a>. Therefore, the quantity is minimized when <span class="math inline">\(c = \mu\)</span>.</p>
<p>As for the mean absolute error, we need to show that <span class="math inline">\(E|X - m| \le E |X - a|\)</span> for any <span class="math inline">\(a\)</span>, which is equivalent to <span class="math inline">\(E(|X - a| - |X - m|) \ge 0\)</span>. Assume <span class="math inline">\(m &lt; a\)</span> without loss of generality, if <span class="math inline">\(X \le m\)</span> then</p>
<p><span class="math display">\[
|X - a| -|X - m| = a-m
\]</span></p>
<p>and if <span class="math inline">\(X &gt; m\)</span></p>
<p><span class="math display">\[
|X - a| - |X - m| \ge X - a - (X- m) = m -a
\]</span></p>
<p>Let</p>
<p><span class="math display">\[
Y  = |X - a| - |X - m|
\]</span></p>
<p>When can split <span class="math inline">\(E(Y)\)</span> into two parts based on whether the event <span class="math inline">\(X \le m\)</span> occurs</p>
<p><span class="math display">\[
\begin{split}
E(Y) &amp;= E(Y | X \le m)P(X \le m) +E(Y | X &gt; m)P(X \gt m) \\
&amp;\ge (a - m)P(X \le m) + (m - a)P(X &gt; m) \\
&amp;= (a-m)P(X \le m) - (a - m)(1 - P(X \le m)) \\
&amp;= (a - m)(2P(X \le m) - 1)
\end{split}
\]</span>
Since for median <span class="math inline">\(m\)</span> we know <span class="math inline">\(P(X \le m) \le \frac{1}{2}\)</span>, we get <span class="math inline">\(E(Y) \ge 0\)</span> with equality when <span class="math inline">\(a = m\)</span>. This means the mean absolute error <span class="math inline">\(E|X - a|\)</span> is minimized when <span class="math inline">\(a\)</span> is the median of <span class="math inline">\(X\)</span>.</p>
</div>
<div id="moment-generating-functions" class="section level2">
<h2><span class="header-section-number">11.3</span> Moment generating functions</h2>

<div class="theorem">
<p><span id="thm:mgf-moment" class="theorem"><strong>Theorem 11.1  (Moments via derivaties of MGF)  </strong></span>The <span class="math inline">\(n\)</span>th momment of r.v. <span class="math inline">\(X\)</span> is the <span class="math inline">\(n\)</span>th derivative of its MGF evaluated at zero</p>
<span class="math display">\[
E(X^n) = M^{n}(0)
\]</span>
</div>


<div class="proof">
Proof
</div>

<p>The Taylor expansion of <span class="math inline">\(M(t)\)</span> about <span class="math inline">\(0\)</span> is</p>
<p><span class="math display">\[
M(t) = \sum_{n=1}^{\infty} M^{(n)}(0) \frac{t^n}{n!}
\]</span></p>
<p>On the other hand, use the fact that the Taylor expansion of <span class="math inline">\(e^x\)</span> about <span class="math inline">\(0\)</span> is <span class="math inline">\(\sum \frac{x^n}{n!}\)</span>, we have</p>
<p><span class="math display">\[
\begin{split}
M(t)  &amp;= E(e^{tX}) \\
&amp;= E(\sum_{n = 0}^{\infty} \frac{X^nt^n}{n!}) \\
&amp;= \sum_{n = 0}^{\infty} E(X^n)\frac{t^n}{n!} \qquad \text{due to techinical conditions of MGF}\\ 
\end{split} 
\]</span></p>
<p>Matching the coefficients of the two expansions, we get <span class="math inline">\(E(X^n) = M^{(n)}(0)\)</span></p>
<p>Note that expectation of infinite sum <span class="math inline">\(E(\sum_{i = 0}^{\infty}X_i)\)</span> may not be equal to <span class="math inline">\(\sum_{n=0}^{\infty}E(X_I)\)</span>. In other words, linearity of expectation may not hold for infinite sums. However, the definition of MGF has a technical condition â€“ MGF is finite on some open interval <span class="math inline">\((-a, a)\)</span> containing <span class="math inline">\(0\)</span> â€“ which ensures the linearity property used in the following formula.</p>

<div class="theorem">
<span id="thm:mgf-distribution" class="theorem"><strong>Theorem 11.2  (One-to-one relationship between MGF and distribution)  </strong></span>The MGF of a random variable determines its distribution. If two random variables have the same MGF, then they follow the same distribution.
</div>


<div class="theorem">
<p><span id="thm:mgf-convolution" class="theorem"><strong>Theorem 11.3  (MGF and convolutions)  </strong></span>The MGF of the convolution (sum) of two independent r.v. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is the product of the individual MGFs. This is because</p>
</div>

<p><span class="math display">\[
\begin{split}
M_{X + Y}(t) &amp;= E(e^{t(X + Y)}) \\
&amp;= E(e^{tX} \cdot e^{tY})\\
&amp;= E(e^{tX}) \cdot E(e^{tY}) \qquad \text{X and Y are independent}\\
&amp;= M_X(t) \cdot M_Y(t)
\end{split}
\]</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Proof: <span class="math inline">\(E(XY) = E(X)E(Y) + \text{Cov}(X, Y)\)</span>. Start with covariance <span class="math display">\[\begin{split}
\text{Cov}(X, Y) &amp;= E[(X - \mu_x)(Y - \mu_y)] \\
&amp;= E(XY - X\mu_y - Y\mu_x + \mu_x\mu_y) \\
&amp;= E(XY) - \mu_yE(X) - \mu_xE(Y) + \mu_x\mu_y \\
&amp;= E(XY) - 2\mu_x\mu_y + \mu_x\mu_y \\
&amp; = E(XY) - \mu_x\mu_y
\end{split}\]</span><a href="random-variables-and-moments.html#fnref4" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn5"><p>Proof: <span class="math inline">\(E(X^2) = \text{Var}(X) + \big( E(X) \big)\)</span>. <span class="math display">\[
\begin{split}
E(X^2) &amp;= E \big[ (X \pm \mu)^2 \big] \\
&amp;= E(X - \mu)^2 + \mu^2 + 2 \mu E(X -\mu) \qquad \text{the 3rd term is zero} \\
&amp;= \text{Var}(X) + [E(X)]^2
\end{split}
\]</span><a href="random-variables-and-moments.html#fnref5" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability-basics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="univariate-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/math-foundations/edit/master/moments.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

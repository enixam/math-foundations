[
["index.html", "Mathematical Foundations Preface", " Mathematical Foundations Qiushi Yan 2020-07-02 Preface This notebook documents my self-study on math foundations of data science, including linear algebra, probability theory, statistics and possibly optimization. Some references (books, online courses, videos, papers) include: Linear Algebra and its Applications (Lay 2006) Linear Algebra Review and Reference on Stanford’s cs229 website Gilbert Strang. 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning. Spring 2018. Massachusetts Institute of Technology: MIT OpenCourseWare, https://ocw.mit.edu. License: Creative Commons BY-NC-SA. "],
["matrix-algebra.html", "Chapter 1 Matrix Algebra ", " Chapter 1 Matrix Algebra "],
["elemetary-matrix-and-row-operations.html", "1.1 Elemetary matrix and row operations", " 1.1 Elemetary matrix and row operations For any \\(x^{T} = [x_1, ..., x_m]^T\\) and matrix \\(A_{m \\times n}\\), \\(x^{T}A\\) can be thought of as a linear combination of rows in \\(A\\) to produce a new row vector: \\[ [x_1, ..., x_m] \\begin{bmatrix} \\boldsymbol{a}_1^T \\\\ \\cdots \\\\ \\boldsymbol{a}_m^T \\end{bmatrix} = x_1\\boldsymbol{a}_1^T + \\dots + x_m\\boldsymbol{a}_m^T \\] An elementary matrix is one that is obtained by performing a single elementary row operation on an identity matrix \\(I\\). Each elementary matrix \\(E\\) is invertible. The inverse of \\(E\\) is the elementary matrix of the same type that transforms \\(E\\) back into \\(I\\). "],
["arithmetic-properties.html", "1.2 Arithmetic properties", " 1.2 Arithmetic properties 1.2.1 Inverse of a matrix Theorem 1.1 If A and B are both invertible matrces, we have \\[ (AB)^{-1} = B^{-1}A^{-1} \\] \\[ (A^{-1})^{-1} = A \\] \\[ (A^T)^{-1} = (A^{-1})^T \\] "],
["lu-factorization.html", "1.3 LU factorization", " 1.3 LU factorization A factorization a matrix A is an equation that expresses A as a product of two or more matrices "],
["subspaces.html", "1.4 4 subspaces", " 1.4 4 subspaces "],
["matrix-multiplication-as-linear-transformation.html", "1.5 Matrix multiplication as linear transformation", " 1.5 Matrix multiplication as linear transformation The equation \\(A_{m \\times n} \\, x _{ n \\times 1} = b_{m \\times 1}\\) can arise in a way that is not directly connected with linear combination of column vectors. That is, we think of the matrix \\(A\\) as an force that “acts” on a vector \\(x\\) in \\(R^n\\) by multiplication to produce a new vector called \\(b\\) in \\(R^m\\). A transformation \\(T\\) from \\(R^n\\) to \\(R^m\\) is a rule that assigns each vector in \\(R^n\\) a vector \\(T(x)\\) in \\(R^m\\), which is called the image of (under the action of \\(T\\)). It can be show that such transformations induced by multiplying a matrix is a type of linear transformation, because it satisfies all required properties to be linear: \\[ \\begin{aligned} \\text{vector addition} \\quad A(\\boldsymbol{u} + \\boldsymbol{v}) &amp;= A\\boldsymbol{u} + A\\boldsymbol{v} \\\\ \\text{scalar multiplication} \\quad A(c\\boldsymbol{u}) &amp;= cA\\boldsymbol{u} \\end{aligned} \\] Theorem 1.2 There is a one to one relationship between a linear transformation and a matrix. Let \\(T: R^n \\rightarrow R^m\\) be a linear transformation. Then there exists a unique matrix \\(A\\) such that: \\[ T(x) = Ax \\quad \\text{for all} \\; x \\; \\text{in} \\; R^n \\] In fact, \\(A\\) is a \\(m \\times n\\) matrix whose \\(j\\)th column is the vector \\(T(\\boldsymbol{e_j})\\), where \\(\\boldsymbol{e_j}\\) is the \\(j\\)th basis of \\(R^n\\) Proof: \\[ \\boldsymbol{x} = x_1\\boldsymbol{e_1} + \\dots + x_n{\\boldsymbol{e_n}} \\] And because \\(T(\\boldsymbol{x})\\) is a linear transformation: \\[ \\begin{split} T(\\boldsymbol{x}) &amp;= x_1T(\\boldsymbol{e_1}) + \\dots + x_nT(\\boldsymbol{e_n}) \\\\ &amp;= [T(\\boldsymbol{e_1}) \\, \\cdots \\, T(\\boldsymbol{e_n})]\\boldsymbol{x} \\\\ &amp;= A\\boldsymbol{x} \\end{split} \\] In other words, the transformation is specified once we know what all basis in \\(R^n\\) become in \\(R^m\\). The matrix \\(A\\) is called the standard matrix for the linear transformation \\(T\\). "],
["eigen-values-and-quadratic-forms.html", "Chapter 2 Eigen values and quadratic forms", " Chapter 2 Eigen values and quadratic forms "],
["references.html", "References", " References Lay, David. 2006. Linear Algebra and Its Applications. Vols. 3:CD-ROM. Pearson, Addison Wesley. "]
]
